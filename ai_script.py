import pandas as pd
from sklearn.preprocessing import StandardScaler
from pycaret.anomaly import *
import category_encoders as ce

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
data_path = "bok_logs_rule_3000.csv"
data = pd.read_csv(data_path, index_col=0).dropna()

# 2. ìˆ«ìí˜• / ë¬¸ìí˜• ë¶„ë¦¬
numeric_cols = data.select_dtypes(include=['int64', 'float64']).columns
categorical_cols = data.select_dtypes(include=['object']).columns

# 3. Frequency Encoding
encoder = ce.CountEncoder()
data_encoded = encoder.fit_transform(data[categorical_cols])

# 4. í•©ì¹˜ê¸° + ìŠ¤ì¼€ì¼ë§
full_data = pd.concat([
    data[numeric_cols].reset_index(drop=True),
    data_encoded.reset_index(drop=True)
], axis=1)
scaler = StandardScaler()
data_scaled = pd.DataFrame(scaler.fit_transform(full_data), columns=full_data.columns)

# 5. PyCaret í™˜ê²½ ì„¤ì • ë° ëª¨ë¸ ìƒì„±
exp = setup(data_scaled, session_id=42, verbose=False, index=False)
model = create_model('iforest')
results = assign_model(model, score=True)

# 6. íƒì§€ ê°œìˆ˜ ì¶œë ¥
count_anomaly = results['Anomaly'].sum()
total = len(results)
print(f"\nğŸ“Œ PyCaretì´ ì´ìƒì¹˜ë¡œ íŒë‹¨í•œ ë¡œê·¸ ê°œìˆ˜: {count_anomaly:,}ê±´ / ì „ì²´ {total:,}ê±´")

# 7. ì´ìƒ íƒì§€ëœ ê²°ê³¼ ì €ì¥
results_detected = results[results['Anomaly'] == 1]
results_detected.to_csv("pycaret_detected_anomalies.csv", index=False)
print(f"âœ… PyCaret ì´ìƒì¹˜ íƒì§€ ê²°ê³¼ {len(results_detected)}ê±´ì´ 'pycaret_detected_anomalies.csv'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")